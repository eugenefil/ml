{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tl;dr Kaiming init fan_out mode is wrong for stride>1 convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example below final gradient variance must be 1 according to paper but in reality it's 25 times smaller. The case is a bit unnatural, you probably wouldn't do stride=5 convolution with kernel size 5, but it illustrates the point well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0103) 0.01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.0415), 0.04, 1.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d, c, k = 4, 3, 5\n",
    "w = torch.empty(d, c, k, k)\n",
    "torch.nn.init.kaiming_normal_(w, mode='fan_out', nonlinearity='relu')\n",
    "w /= 2**.5 # divide by sqrt(2) gain, since we test on 1 layer w/out relu\n",
    "var_w = 1/(k*k*d) # expected variance of w\n",
    "print(w.var(), var_w)\n",
    "x = torch.randn(1, c, 400, 400, requires_grad=True)\n",
    "y = F.conv2d(x, w, stride=k)\n",
    "# delta(y_l) is mean=0,std=1, so var(delta(x)) should be n_hat*var(w) = k^2*d*var(w)\n",
    "y.backward(torch.randn_like(y))\n",
    "x.grad.var(), var_w*d, var_w*k*k*d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas for stride=1 it's fine, we get variance of 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0119)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y = F.conv2d(x, w, stride=1)\n",
    "y.backward(torch.randn_like(y))\n",
    "x.grad.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with stride=k is that n_hat in such (worst) cases equals d instead of k^2d. If we account for this, we get grad variance 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2535) 0.25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.0309), 1.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_w = 1/d # instead of 1/(k*k*d)\n",
    "w.normal_(0, var_w**.5)\n",
    "print(w.var(), var_w)\n",
    "x = torch.randn(1, c, 400, 400, requires_grad=True)\n",
    "y = F.conv2d(x, w, stride=k)\n",
    "y.backward(torch.randn_like(y))\n",
    "x.grad.var(), var_w*d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When 1<stride<k we get something between the worst and the best cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Details: when and why $\\hat{n}$ is not $k^2d$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In essence the problem is that during backward pass convolution stride and image size also influence the variance of gradient, while Kaiming derivation assumes stride=1 and big (compared to kernel size) image size. Experiments below show, that when those assumptions are violated, Kaiming formula for gradient variance doesn't hold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate variance of y_L and delta(x1) for L conv layers\n",
    "def conv_variance(L=1, imsize=100, ch=3, k=3, stride=1):\n",
    "    # batch of 1 input square image, var(x1)==1\n",
    "    x1 = torch.randn(1, ch, imsize, imsize, requires_grad=True)\n",
    "    # for simplicity input channels c == output channels d == ch\n",
    "    w = torch.randn(ch, ch, k, k) # var(w)==1\n",
    "\n",
    "    x = x1\n",
    "    for _ in range(L):\n",
    "        y = F.conv2d(x, w, stride=stride)\n",
    "        x = F.relu(y)\n",
    "    \n",
    "    # instead of getting grads from loss func we use mean=0,std=1 grads directly\n",
    "    # for last layer delta(x_L) calculation, i.e. var(delta(y_L))==1\n",
    "    delta_y_L = torch.randn_like(y)\n",
    "    y.backward(delta_y_L)\n",
    "    return y.var().item(), x1.grad.var().item()\n",
    "\n",
    "# run conv_variance 100 times and return mean results\n",
    "def test(*args, **kws):\n",
    "    N = 100\n",
    "    yvar, dvar = 0., 0.\n",
    "    for _ in range(N):\n",
    "        yv, dv = conv_variance(*args, **kws)\n",
    "        yvar += yv\n",
    "        dvar += dv\n",
    "    return {'var(y_L)':yvar/N, 'var(delta(x1))':dvar/N}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conv_variance() kernel size k and num of input/output channels c,d are the same for all layers (i.e. $n = k^2c = \\hat{n} = k^2d$) and also $var(x_1) = 1$, $var(\\Delta y_L) = 1$, $var(w) = 1$, so according to paper final layer variance and first layer grad variance MUST BE equal:\n",
    "\n",
    "$$\n",
    "var(y_L) = n\\,var(w)\\,var(x_1) \\prod_{l=2}^{L}\\frac{1}{2}n\\,var(w) = n \\prod_{l=2}^{L}\\frac{1}{2}n = \\frac{n^L}{2^{L-1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "var(\\Delta x_1) = n\\,var(w)\\,var(\\Delta y_L) \\prod_{l=L-1}^{1}\\frac{1}{2}n\\,var(w) = n \\prod_{l=L-1}^{1}\\frac{1}{2}n = \\frac{n^L}{2^{L-1}}\n",
    "$$\n",
    "\n",
    "For L=1 $var(y_L) = var(\\Delta x_1) = n = k^2c$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var(y_L)': 27.046004705429077, 'var(delta(x1))': 25.973986530303954}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(L=1, imsize=100, ch=3, k=3) # n=27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variances above are close, but grad variance is always a bit smaller. That's because only inner input pixels get k^2d gradients. Outer pixels get less grads, so their variance is less than k^2d, in turn making overall gradient variance smaller than k^2d."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With bigger image size w.r.t. kernel size outer pixels become negligible, so y_L and delta(x1) variances are even closer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var(y_L)': 26.860750179290772, 'var(delta(x1))': 26.754636344909667}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(L=1, imsize=1000, ch=3, k=3) # n=27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even more closer with smaller kernel size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var(y_L)': 12.026659684181213, 'var(delta(x1))': 11.999356188774108}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(L=1, imsize=1000, ch=3, k=2) # n=12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But when kernel size is comparable to image size, only a few input pixels at the image center get k^2d grads, so real $\\hat{n}$ is between d and k^2d:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var(y_L)': 27.256405773162843, 'var(delta(x1))': 13.555154795646667}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(L=1, imsize=7, ch=3, k=3) # n=27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the extreme case image size equals kernel size, so each input pixel is used in exactly one output pixel and thus gets back one gradient of variance d, hence real $\\hat{n}=d$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var(y_L)': 27.152843496501447, 'var(delta(x1))': 3.3247227012366056}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(L=1, imsize=3, ch=3, k=3) # n=27, real n_hat=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same happens when stride equals kernel size - each input pixel is used only once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var(y_L)': 26.94449602127075, 'var(delta(x1))': 2.9340525698661803}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(L=1, imsize=100, ch=3, k=3, stride=3) # n=27, real n_hat=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When stride is not 1, but less than kernel size, some fraction of input pixels is used more than once, so get more than d but less than k^2d grads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var(y_L)': 47.99311561584473, 'var(delta(x1))': 3.0068949675559997}\n",
      "{'var(y_L)': 47.557743053436276, 'var(delta(x1))': 5.1832145404815675}\n",
      "{'var(y_L)': 47.56187725067139, 'var(delta(x1))': 11.376869382858276}\n",
      "{'var(y_L)': 47.71765846252441, 'var(delta(x1))': 44.87692974090576}\n"
     ]
    }
   ],
   "source": [
    "# n=4*4*3=48, real n_hat is inside interval (3,48)\n",
    "print(test(L=1, imsize=100, ch=3, k=4, stride=4))\n",
    "print(test(L=1, imsize=100, ch=3, k=4, stride=3))\n",
    "print(test(L=1, imsize=100, ch=3, k=4, stride=2))\n",
    "print(test(L=1, imsize=100, ch=3, k=4, stride=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For several layers all of the above holds, but things get much noisier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var(y_L)': 4315.193284301758, 'var(delta(x1))': 6.674200213253498}\n",
      "{'var(y_L)': 4921.608842010498, 'var(delta(x1))': 79.8527949142456}\n",
      "{'var(y_L)': 5323.199635009765, 'var(delta(x1))': 6091.3666088867185}\n"
     ]
    }
   ],
   "source": [
    "# n=27**3/4=4920, real n_hat is inside (3**3/4,27**3/4) = (7,4920)\n",
    "L = 3\n",
    "print(test(L, imsize=500, ch=3, k=3, stride=3))\n",
    "print(test(L, imsize=500, ch=3, k=3, stride=2))\n",
    "print(test(L, imsize=500, ch=3, k=3, stride=1))"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/37968b92820701f8344b6763a279e522"
  },
  "gist": {
   "data": {
    "description": "kaiming-init.ipynb",
    "public": true
   },
   "id": "37968b92820701f8344b6763a279e522"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
