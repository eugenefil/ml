{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip,pickle\n",
    "import mytorch\n",
    "import myai\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr,va,te=pickle.load(gzip.open('data/mnist.pkl.gz'),encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.99609375, 0.13044983, 0.3072898)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize(x,mean,std): return (x-mean)/std\n",
    "tr_mean,tr_std=tr[0].mean(),tr[0].std()\n",
    "def denorm(x): return x*tr_std+tr_mean\n",
    "tr[0].min(),tr[0].max(),tr_mean,tr_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.1638146e-07, 0.99999934, -0.005850922, 0.99243325, 0.005034822, 1.0064359)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr=(normalize(tr[0],tr_mean,tr_std),tr[1])\n",
    "va=(normalize(va[0],tr_mean,tr_std),va[1])\n",
    "te=(normalize(te[0],tr_mean,tr_std),te[1])\n",
    "tr[0].mean(),tr[0].std(),va[0].mean(),va[0].std(),te[0].mean(),te[0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.99609375, -0.42451727, 2.8170278)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denorm(tr[0]).min(),denorm(tr[0]).max(),tr[0].min(),tr[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_in=te[0].shape[1]\n",
    "n_out=te[1].max()+1\n",
    "n_in,n_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resize(mytorch.Module):\n",
    "    def forward(self,x): return x.reshape((-1,1,28,28))\n",
    "class Flatten(mytorch.Module):\n",
    "    def forward(self,x): return x.reshape((len(x),-1))\n",
    "\n",
    "def getm():\n",
    "    return mytorch.Seq(\n",
    "        Resize() # 784 -> 1x28x28\n",
    "        ,mytorch.Conv2d(1,8,5,padding=2,stride=2),mytorch.ReLU() #14\n",
    "        ,mytorch.Conv2d(8,16,3,padding=1,stride=2),mytorch.ReLU() #7\n",
    "        ,mytorch.Conv2d(16,32,3,padding=1,stride=2),mytorch.ReLU() #4\n",
    "        ,Flatten()\n",
    "        ,mytorch.Linear(32*4*4,n_out)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeCallback:\n",
    "    def before_fit(self): self.t0=time()\n",
    "    def after_fit(self): print('total time ',time()-self.t0,'s',sep='')\n",
    "        \n",
    "class StatsCallback:\n",
    "    def before_epoch(self): self.tr_loss,self.val_loss,self.acc=0,0,0\n",
    "    def after_loss(self):\n",
    "        if self.learn.training:\n",
    "            self.tr_loss+=self.learn.loss.item()*len(self.learn.xb)\n",
    "        else:\n",
    "            self.acc+=(self.learn.preds.argmax(axis=1)==self.learn.yb).sum().item()\n",
    "            self.val_loss+=self.learn.loss.item()*len(self.learn.xb)\n",
    "    def after_epoch(self):\n",
    "        print('train loss',self.tr_loss/len(tr[0]))\n",
    "        print('valid loss',self.val_loss/len(va[0]))\n",
    "        print('accuracy',self.acc/len(va[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev='cpu'\n",
    "if mytorch.cuda_is_available(): dev='cuda'\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "lr=.1\n",
    "n_ep=3\n",
    "\n",
    "def getdl(x,y,shuffle=False,first_n=None):\n",
    "    if first_n: x,y=x[:first_n],y[:first_n]\n",
    "    x,y=map(lambda x:mytorch.tensor(x,device=dev),[x,y])\n",
    "    ds=mytorch.TensorDataset(x,y)\n",
    "    return mytorch.DataLoader(ds,bs=batch_size,shuffle=shuffle)\n",
    "\n",
    "trdl=getdl(*tr,shuffle=True)\n",
    "valdl=getdl(*va)\n",
    "m=getm().to(dtype=mytorch.float32,device=dev)\n",
    "opt=mytorch.SGD(m.params(),lr,set_to_none=True)\n",
    "lrn=myai.Learner(trdl,m,opt,mytorch.cross_entropy,valdl=valdl,\n",
    "            cbs=[TimeCallback(),StatsCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.2792095726951957\n",
      "valid loss 0.11150240968447178\n",
      "accuracy 0.9685\n",
      "train loss 0.10175056593865156\n",
      "valid loss 0.08823755176505074\n",
      "accuracy 0.9757\n",
      "train loss 0.07689579922147095\n",
      "valid loss 0.08139400115702301\n",
      "accuracy 0.9757\n",
      "total time 7.828434705734253s\n"
     ]
    }
   ],
   "source": [
    "lrn.fit(n_ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.5143283933699131\n",
      "0.9621 0.1388060618750751\n",
      "train loss 0.12304508703574538\n",
      "0.9679 0.11211160973645747\n",
      "train loss 0.0891373685207218\n",
      "0.978 0.07642323927721009\n",
      "9.099228382110596 s\n"
     ]
    }
   ],
   "source": [
    "class Resize(nn.Module):\n",
    "    def forward(self,x): return x.reshape((-1,1,28,28))\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self,x): return x.reshape((len(x),-1))\n",
    "def getm():\n",
    "    return nn.Sequential(\n",
    "        Resize() # 784 -> 1x28x28\n",
    "        ,nn.Conv2d(1,8,5,padding=2,stride=2),nn.ReLU() #14\n",
    "        ,nn.Conv2d(8,16,3,padding=1,stride=2),nn.ReLU() #7\n",
    "        ,nn.Conv2d(16,32,3,padding=1,stride=2),nn.ReLU() #4\n",
    "        ,Flatten()\n",
    "        ,nn.Linear(32*4*4,n_out)\n",
    "    )\n",
    "\n",
    "def getdl(x,y,shuffle=False,first_n=None):\n",
    "    if first_n: x,y=x[:first_n],y[:first_n]\n",
    "    x,y=map(lambda x:torch.tensor(x,device=dev),[x,y])\n",
    "    ds=TensorDataset(x,y)\n",
    "    return DataLoader(ds,batch_size=batch_size,shuffle=shuffle)\n",
    "\n",
    "trdl=getdl(*tr,shuffle=True)\n",
    "valdl=getdl(*va)\n",
    "m=getm().to(device=dev)\n",
    "opt=optim.SGD(m.parameters(),lr)\n",
    "t0=time()\n",
    "for ep in range(n_ep):\n",
    "    totloss=0.\n",
    "    for xb,yb in trdl:\n",
    "        loss=F.cross_entropy(m(xb),yb)\n",
    "        totloss+=loss.item()*len(xb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    print('train loss',totloss/len(tr[0]))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loss=0.\n",
    "        acc=0.\n",
    "        for xb,yb in valdl:\n",
    "            yhat=m(xb)\n",
    "            acc+=(yhat.argmax(axis=1)==yb).sum().item()\n",
    "            loss+=F.cross_entropy(yhat,yb).item()*len(xb)\n",
    "        print(acc/len(va[0]),loss/len(va[0]))\n",
    "print(time()-t0,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
